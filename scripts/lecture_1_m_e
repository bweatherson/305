This is going to be a longer than usual lecture, introducing how derivations work in Carnap. The reason that it's long is that I wanted to work through one full example from start to finish, and there weren't any natural breaks in the middle of it.

<new slide>

A derivation is a series of steps that get you from the premises to the conclusion, with every step being an instance of one of a small number of approved kinds of transition. I'll illustrate this, and explain some of the rules.

<new slide>

The philosophical idea behind them is that the steps are small enough that we can see each step can't be the first misstep of the proof. Every step is such that if you've made no mistakes before it, it also isn't a mistake. It can't be the one that takes you from truth to falsity.

And that means that you can string together any number of them.

It really matters that what we have here is a guarantee. If every step was 99.99% likely to preserve truth, then after ten thousand steps, you'd probably have gone wrong. And computer programs, for instance, can go through ten thousand steps in a blink of an eye. We really want something that never goes from truth to falsity, not something that almost never does. And that's what we'll aim for.

<new slide> 

Here is the example we're going to work through. It is not intrinsically interesting; the point is to illustrate how proofs work. It has two premsies. The first is P. The second is a conditional, that says that if not not P is true, then so is not not Q. And the conclusion is Q.

<new slide>

We can give an intuitive argument for this conclusion. First, assume that the two premises are true. When we analyse arguments we always take the premises for granted.

<new slide>

If P is true, then not not P is true. Whatever is true is not not true, so if P is true, it is not not true.

<new slide>

But P is true, so we can infer not not P.

<new slide>

Now if not not P is true and if not not P then not not Q are true, we can infer not not Q.

<new slide>

So we can infer not not Q.

<new slide>

And if it isn't the case that not Q, it must be the case that Q. So Q is true, as required.

<new slide>

Here is how the argument looks in Carnap. I'm going to go over it step by step, but the big picture is going to be that the formal proof really mirrors the informal proof I just offered.

<new slide> 

A lot of what I'm going to say over the next few slides is about **Carnap**, not about logic in general. Logic, in the way we're doing it, is a very young subject. We haven't got a stable set of conventions on how to do various things. So at every stage you have to learn how a particular textbook does things. Happily, once you've learned one it is easy to learn the others. But some of the things I'm going to fuss about here are really idiosyncratic.

<new slide>

What we're learning here is a version of what is known as a **natural deduction** proof system. It is somewhat non-standard, but that's not to say any one way is standard. Every system I know is idiosyncratic in one way or another. It's like saying that a particular car has some unusual features, without saying there is such a thing as a usual car.

<new slide>

What is common to all natural deduction systems is that when you read the steps, they read like a (pedantic version of) ordinary language reasoning. And that's what we'll see in this case.

<new slide>

The most idiosyncratic feature of Carnap is how it starts and ends derivations.

<new slide> 

In Carnap, you have to start a proof by announcing where you are headed. That's the "Show" step at the start.

<new slide>

And you end the proof by saying which line it is that the conclusion is reached. That's the DD 6. It means I finished the proof on line 6.

<new slide>

Note that these are the only two lines that are not indented. Proof systems (Carnap included) are visual, graphic systems, and vertical and horizontal arrangements tend to have meaning.

<new slide>

They are also the only lines here that do not have a justification. All those letters and numbers in the right hand column are justifications, but you don't have to justify where you're going, or the fact that you got there.

<new slide>

The `DD' at the end is to indicate this is a **direct** derivation. We'll get to the contrast with indirect derivations in the next lecture.

<new slide

OK, once we've announced where we're going, we start with the premises. At least, we start with the premises if there are any premises. We'll get to zero premise arguments in a bit. But if an argument has premises, they go first.

<new slide

The premises need to be noted - that's what the 'PR' is for - but they are not derived. They are sort of self-justifying. Really what this means is that the justification is elsewhere.

<new slide>

Your justification for writing them is that they are the beginning of what you are trying to prove.

<new slide>

So they don't get line numbers afterwards, because they don't come from inside the proof.

<new slide>

All the subsequent lines are derived from previous lines. And when you do a derivation, you have to say what rule you are using, and what lines provide the input to that rule.

<new slide>

Carnap uses these fancy indenting conventions to indicate different things. The premises and the derived lines are indented by four spaces. For reasons I don't completely understand, hitting tab to do the indent probably won't work. It's gotta be four spaces. Essentially Carnap is using a kind of markdown syntax, and four spaces is often a meaningful signal in markdown. But you don't need to know why it matters, just that four spaces are used here.

<new slide>

All that was setup, but we're now onto what I think of as the real heart of the system, the rules.

The first rule we'll look at is called Double Negation Introduction. It says that if you've got a line, you can create a new line with the same sentence on it, but with two negations in the front.

<new slide>

The abbreviation for the rule is Dee En Eye, short for Double Negation Introduction. And you justify it by saying the line where the original sentence appears.

<new slide>

You can actually do entire proofs using just this rule. 

The point of this example is that the justification lines can be any line you like. They don't have to be premises.

Put another way, the key thing to know here is that the justifications are immediate justification. You don't have to say where the justification ultimately comes from, just what the immediately preceding step was.

<new slide>

A rule says that given sentences of some form, another particular sentence can be written.

<new slide>

To apply any rule correctly, you have to do 3 things

You have to write down the correct sentence, given the constraints of the rule.

You have to write down (immediately after a colon) the abbreviation for the rule.

And you have to write down the line, or lines, that provide the inputs.

<new slide> 

So let's check that we satisfied all three of those constraints.

The first says that if our input is P, our output has to be not not P. And it is, so that's good.

<new slide> 

The second says we have to use the right abbreviation for the rule. And the abbreviation for Double Negation Introduction is DNI - which is what we wrote.

<new slide>

And the input, the line we are adding not not to, is line 2, so we write '2'. So we applied the rule correctly.

<new slide>

Here's a case where the rule for DNI was applied incorrectly. What did we do wrong? Think about it for just a bit, and then I'll answer.

<music break>

<new slide>

You have to add the two negations to **the whole sentence**. Here we added them to one half of the sentence. A correct application of DNI would be this hard to read thing on the screen: not not (P \rightarrow Q)

<new slide>

OK, onto a new rule. The rule at line 5 is the most important in this part of the course. It even gets a fancy Latin name: Modus Ponens.

<new slide>

The rule says that if you have an if then sentence, and you have the if part, you can infer the then part. That sounds plausible I hope.

<new slide>

The abbreviation for this rule is MP. The lines you have to cite are the lines where the if then statement is, and where the if part is. It doesn't matter which order you put them in. 

<new slide>

And as I stressed earlier, you don't have to cite the premises that justify the lines. Just cite the if then line, and the line with the if part.

What this means is that these lines are the immediate justification for what you're writing. We don't worry about their ultimate justification.

<new slide>

With all of these rules, it is really important to apply them to whole sentences. What I've been calling the if then sentence has to have the arrow as its main connective.

<new slide>

On the left is an example where we get things right. From P, and If P, Q or R, we can infer Q or R.

On the right is an example where things go wrong. Because the arrow is not the main connective in line 2, we can't use the arrow rule on line 2.

<new slide>

I haven't included this in the example, but there is another rule with a fancy Latin name: modus tollens. The inputs to it are a conditional, and the negation of the then part of the conditional. The output is the negation of the if part. If I know that if it rained, the streets are wet, and the streets aren't wet, I can infer that it didn't rain. That's the idea.

<new slide>

It's helpful at this stage to have terms for the parts of a conditional. We'll use the word **antecedent** for the left hand side, the if part, and **consequent** for the then part.

Which is the if part and which is the then part is more significant than which is the first part or second part, or the left part of the right part. In English you can put the two parts in any order you like. You can say things in the same order as the conditional, e.g., If it rains, the streets get wet, but you can also say the same thing the other way around, e.g., the streets get wet if it rains.

<new slide>

One last rule for this proof: Double Negation Elimination. It lets you go from not not something, to that thing. Its abbreviation is DNE. And because there is only one input, there is only one line cited.

<new slide>

And we're done. Since we've got to a line that matches what was to be shown, we have a complete `direct derivation'.

<new slide>

I'm not going to read these out, because they make more sense on paper than in words, but here is a reminder slide of the four rules that we have learned.

<new slide> 

And remember these things. First, rules have to apply to whole sentences. Second, you cite the lines that provide the immediate justification for what you write down.

<new slide> 

And if you're still having problems with Carnap, remember that it gets very fussy about spacing. We have to use four spaces for indented sentences, no spaces after colons, one space after the abbreviation for the rule.

This isn't because this is some deep fact about how to do logic. It's about how this computer program works.

What is a deep fact about logic is that we get some really substantive, important results by being really attentive to the precise details of what we write down. At the end of the day, we get a system whose rules are so simple that a 1960s computer could assess whether they are being applied correctly, but which can do incredibly powerful reasoning.

<new slide>

For next time, we'll move to the next kind of proof: Indirect Derivations.