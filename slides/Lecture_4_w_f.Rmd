---
title: "305 Lecture 44 - Convergence Theorems"
author: "Brian Weatherson"
date: "July 29, 2020"
output: 
  beamer_presentation:
    md_extensions: +link_attributes
    keep_tex: true
    latex_engine: xelatex
    includes:
      in_header: 305-beamer-header.tex
---

## Plan

- We're going to talk about why different priors might not matter - because they usually converge to the same thing.

## Associated Reading

This isn't in the book; we'll return to its narrative next time.

## Big Picture

- Maybe there is no one true prior.
- But not anything goes.
- And the ones that are ok are all such that they will converge to the truth given enough evidence.

## Convergence

- I am really not going to go over the details of this.
- But it turns out there are a large class of functions with the following feature.
- According to any function in the class, the probability that evidence will come in that makes every function in the class get arbitrarily close is very high.

## Intuitive Case

Imagine that I know a coin is biased in 1 of 2 ways.

1. Each flip has probability 0.8 of landing heads.
2. Each flip has probability 0.2 of landing heads.

Then I get to flip the coin 100 times. What will happen?

## Convergence

- On scenario 1, the probability that I'll get at least 60 heads is greater than 0.99999.
- But on scenaio 2, the probability of that is less than $10^{-10}$.
- So if I start out 50/50 between the options, and get more than 60 heads, I'll end up massively leaning towards scenario 1. \pause
- But imagine Calum starts out thinking that option 2 is really likely - 0.99 likely and option 1 only 0.01.
- He will also get to the right view after 100 trials - even 60 heads (which is really low on scenario 1) would be enough to change the probabilities.

## General Principle

As long as we don't start with probability 0 for one or other scenario, get enough evidence and we'll converge to the correct scenario.

## Two Problem Cases

1. There isn't enough evidence around. This is a big problem in thinking about history, and also about social sciences.
2. People do start with probability 0 for various scenarios.

## Optimistic Take

- These two problems won't arise very often.
- So updating by conditionalisation will lead us to converge.
- That's the sense in which we get objectivity; subjective priors that are sufficiently responsive to the evidence end up being objective enough.

## For Next Time

- We will end this unit by looking at a common scientific practice - significance testing.